{"nbformat":4,"nbformat_minor":0,"metadata":{"jupytext":{"split_at_heading":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"name":"new_skr_40_tabular.core.ipynb","provenance":[],"collapsed_sections":["HgAeYLwnO07q","HAjW3D4sO07u"]}},"cells":[{"cell_type":"code","metadata":{"id":"UiXsSzUNO03u","executionInfo":{"status":"ok","timestamp":1604245151446,"user_tz":480,"elapsed":83057,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"b2a6f2fa-69a9-4f6f-954d-349ea9ad4158","colab":{"base_uri":"https://localhost:8080/"}},"source":["# make your Google drive accessible \n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","root_dir = \"/content/gdrive/My Drive/\"\n","base_dir = root_dir + 'fastai2_library/course-v4/'\n","\n","# navigate to the notebooks directory for dl2\n","import os\n","os.chdir(base_dir)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HpYRrvrXPUnO","executionInfo":{"status":"ok","timestamp":1604245158218,"user_tz":480,"elapsed":2429,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"22191802-3e67-46ed-f7a7-672774295652","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pwd\n","# cd to base_dir if above os.chdir does not work using below command\n","# %cd \"/content/gdrive/My Drive/fastai2_library/course-v4/\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/fastai2_library/course-v4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7FS83lGEPG11","executionInfo":{"status":"ok","timestamp":1604245276119,"user_tz":480,"elapsed":114419,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"790dd819-f3f3-4cac-9b9a-3a46f6a7c92e","colab":{"base_uri":"https://localhost:8080/"}},"source":["#hide\n","#skip\n","! [[ -e /content ]] && pip install -Uqq fastai  # upgrade fastai on colab"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 194kB 3.2MB/s \n","\u001b[K     |████████████████████████████████| 51kB 4.4MB/s \n","\u001b[K     |████████████████████████████████| 776.7MB 23kB/s \n","\u001b[K     |████████████████████████████████| 12.8MB 41.3MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nZTvE1UqPcGu","executionInfo":{"status":"ok","timestamp":1604245298520,"user_tz":480,"elapsed":2537,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"1d890da4-7e3f-4ada-ce42-c5f2299a79ba","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd nbs"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/fastai2_library/course-v4/nbs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m6-8--Y0O030"},"source":["#default_exp tabular.core"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Rn8ZgCOO033","executionInfo":{"status":"ok","timestamp":1604245306213,"user_tz":480,"elapsed":3171,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","from fastai.torch_basics import *\n","from fastai.data.all import *"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xba16QMFO036"},"source":["#hide\n","from nbdev.showdoc import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9TgIxe42O039","executionInfo":{"status":"ok","timestamp":1604245311411,"user_tz":480,"elapsed":2418,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","pd.set_option('mode.chained_assignment','raise')"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Qo7jXo3O04B"},"source":["# Tabular core\n","\n","> Basic function to preprocess tabular data before assembling it in a `DataLoaders`."]},{"cell_type":"markdown","metadata":{"id":"TYlEsRHEO04B"},"source":["## Initial preprocessing"]},{"cell_type":"code","metadata":{"id":"0vbNiXArO04C","executionInfo":{"status":"ok","timestamp":1604245338326,"user_tz":480,"elapsed":2100,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","def make_date(df, date_field):\n","    \"Make sure `df[date_field]` is of the right date type.\"\n","    field_dtype = df[date_field].dtype\n","    if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n","        field_dtype = np.datetime64\n","    if not np.issubdtype(field_dtype, np.datetime64):\n","        df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"oAk8CyjsO04F","executionInfo":{"status":"ok","timestamp":1604245347427,"user_tz":480,"elapsed":2150,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["df = pd.DataFrame({'date': ['2019-12-04', '2019-11-29', '2019-11-15', '2019-10-24']})\n","make_date(df, 'date')\n","test_eq(df['date'].dtype, np.dtype('datetime64[ns]'))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"zL8p4qOFO04J","executionInfo":{"status":"ok","timestamp":1604245351615,"user_tz":480,"elapsed":1190,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","def add_datepart(df, field_name, prefix=None, drop=True, time=False):\n","    \"Helper function that adds columns relevant to a date in the column `field_name` of `df`.\"\n","    make_date(df, field_name)\n","    field = df[field_name]\n","    prefix = ifnone(prefix, re.sub('[Dd]ate$', '', field_name))\n","    attr = ['Year', 'Month', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',\n","            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n","    if time: attr = attr + ['Hour', 'Minute', 'Second']\n","    for n in attr: df[prefix + n] = getattr(field.dt, n.lower())\n","    # Pandas removed `dt.week` in v1.1.10\n","    week = field.dt.isocalendar().week if hasattr(field.dt, 'isocalendar') else field.dt.week\n","    df.insert(3, prefix+'Week', week)\n","    mask = ~field.isna()\n","    df[prefix + 'Elapsed'] = np.where(mask,field.values.astype(np.int64) // 10 ** 9,None)\n","    if drop: df.drop(field_name, axis=1, inplace=True)\n","    return df"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"iMapIzb_O04M","executionInfo":{"status":"ok","timestamp":1604245363997,"user_tz":480,"elapsed":2459,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"3bce3486-72e0-4ba3-c15b-e93d8ce686ac","colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["df = pd.DataFrame({'date': ['2019-12-04', None, '2019-11-15', '2019-10-24']})\n","df = add_datepart(df, 'date')\n","test_eq(df.columns, ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start', \n","            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start', 'Elapsed'])\n","test_eq(df[df.Elapsed.isna()].shape,(1, 13))\n","df.head()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Year</th>\n","      <th>Month</th>\n","      <th>Week</th>\n","      <th>Day</th>\n","      <th>Dayofweek</th>\n","      <th>Dayofyear</th>\n","      <th>Is_month_end</th>\n","      <th>Is_month_start</th>\n","      <th>Is_quarter_end</th>\n","      <th>Is_quarter_start</th>\n","      <th>Is_year_end</th>\n","      <th>Is_year_start</th>\n","      <th>Elapsed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2019.0</td>\n","      <td>12.0</td>\n","      <td>49</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>338.0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>1575417600</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2019.0</td>\n","      <td>11.0</td>\n","      <td>46</td>\n","      <td>15.0</td>\n","      <td>4.0</td>\n","      <td>319.0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>1573776000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2019.0</td>\n","      <td>10.0</td>\n","      <td>43</td>\n","      <td>24.0</td>\n","      <td>3.0</td>\n","      <td>297.0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>1571875200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Year  Month  Week  ...  Is_year_end  Is_year_start     Elapsed\n","0  2019.0   12.0    49  ...        False          False  1575417600\n","1     NaN    NaN  <NA>  ...        False          False        None\n","2  2019.0   11.0    46  ...        False          False  1573776000\n","3  2019.0   10.0    43  ...        False          False  1571875200\n","\n","[4 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"wxxu6O2WO04Q","executionInfo":{"status":"ok","timestamp":1604245376153,"user_tz":480,"elapsed":2678,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","def _get_elapsed(df,field_names, date_field, base_field, prefix):\n","    for f in field_names:\n","        day1 = np.timedelta64(1, 'D')\n","        last_date,last_base,res = np.datetime64(),None,[]\n","        for b,v,d in zip(df[base_field].values, df[f].values, df[date_field].values):\n","            if last_base is None or b != last_base:\n","                last_date,last_base = np.datetime64(),b\n","            if v: last_date = d\n","            res.append(((d-last_date).astype('timedelta64[D]') / day1))\n","        df[prefix + f] = res\n","    return df"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"FT6uW4tVO04T","executionInfo":{"status":"ok","timestamp":1604245386760,"user_tz":480,"elapsed":1356,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","def add_elapsed_times(df, field_names, date_field, base_field):\n","    \"Add in `df` for each event in `field_names` the elapsed time according to `date_field` grouped by `base_field`\"\n","    field_names = list(L(field_names))\n","    #Make sure date_field is a date and base_field a bool\n","    df[field_names] = df[field_names].astype('bool')\n","    make_date(df, date_field)\n","\n","    work_df = df[field_names + [date_field, base_field]]\n","    work_df = work_df.sort_values([base_field, date_field])\n","    work_df = _get_elapsed(work_df, field_names, date_field, base_field, 'After')\n","    work_df = work_df.sort_values([base_field, date_field], ascending=[True, False])\n","    work_df = _get_elapsed(work_df, field_names, date_field, base_field, 'Before')\n","\n","    for a in ['After' + f for f in field_names] + ['Before' + f for f in field_names]:\n","        work_df[a] = work_df[a].fillna(0).astype(int)\n","\n","    for a,s in zip([True, False], ['_bw', '_fw']):\n","        work_df = work_df.set_index(date_field)\n","        tmp = (work_df[[base_field] + field_names].sort_index(ascending=a)\n","                      .groupby(base_field).rolling(7, min_periods=1).sum())\n","        tmp.drop(base_field,1,inplace=True)\n","        tmp.reset_index(inplace=True)\n","        work_df.reset_index(inplace=True)\n","        work_df = work_df.merge(tmp, 'left', [date_field, base_field], suffixes=['', s])\n","    work_df.drop(field_names,1,inplace=True)\n","    return df.merge(work_df, 'left', [date_field, base_field])"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"BupMZmHmO04W","executionInfo":{"status":"ok","timestamp":1604245399220,"user_tz":480,"elapsed":2434,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"87d78240-ae92-4bcd-9a61-baaa7fc81a0a","colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["df = pd.DataFrame({'date': ['2019-12-04', '2019-11-29', '2019-11-15', '2019-10-24'],\n","                   'event': [False, True, False, True], 'base': [1,1,2,2]})\n","df = add_elapsed_times(df, ['event'], 'date', 'base')\n","df"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>event</th>\n","      <th>base</th>\n","      <th>Afterevent</th>\n","      <th>Beforeevent</th>\n","      <th>event_bw</th>\n","      <th>event_fw</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2019-12-04</td>\n","      <td>False</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2019-11-29</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2019-11-15</td>\n","      <td>False</td>\n","      <td>2</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2019-10-24</td>\n","      <td>True</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        date  event  base  Afterevent  Beforeevent  event_bw  event_fw\n","0 2019-12-04  False     1           5            0       1.0       0.0\n","1 2019-11-29   True     1           0            0       1.0       1.0\n","2 2019-11-15  False     2          22            0       1.0       0.0\n","3 2019-10-24   True     2           0            0       1.0       1.0"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"K0kuee-WO04Z","executionInfo":{"status":"ok","timestamp":1604247149023,"user_tz":480,"elapsed":3774,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","def cont_cat_split(df, max_card=20, dep_var=None):\n","    \"Helper function that returns column names of cont and cat variables from given `df`.\"\n","    cont_names, cat_names = [], []\n","    for label in df:\n","        if label in L(dep_var): continue\n","        if df[label].dtype == int and df[label].unique().shape[0] > max_card or df[label].dtype == float:\n","            cont_names.append(label)\n","        else: cat_names.append(label)\n","    return cont_names, cat_names"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"cY7awPFZO04b","executionInfo":{"status":"ok","timestamp":1604247359486,"user_tz":480,"elapsed":2618,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["df = pd.DataFrame({'cat1': [1, 2, 3, 4], 'cont1': [1., 2., 3., 2.], 'cat2': ['a', 'b', 'b', 'a'], \n","                   'y1': [1, 0, 1, 0], 'y2': [1, 1, 1, 0]})\n","\n","# Test all columns\n","cont, cat = cont_cat_split(df)\n","test_eq((cont, cat), (['cont1'], ['cat1', 'cat2', 'y1', 'y2']))\n","\n","# Test exclusion of dependent variable\n","cont, cat = cont_cat_split(df, dep_var='y1')\n","test_eq((cont, cat), (['cont1'], ['cat1', 'cat2', 'y2']))\n","\n","# Test exclusion of multi-label dependent variables\n","cont, cat = cont_cat_split(df, dep_var=['y1', 'y2'])\n","test_eq((cont, cat), (['cont1'], ['cat1', 'cat2']))\n","\n","# Test maximal cardinality bound for int variable\n","# Any cat col with more than max card will be treated as a cont col hence below\n","cont, cat = cont_cat_split(df, max_card=2, dep_var=['y1', 'y2'])\n","test_eq((cont, cat), (['cat1', 'cont1'], ['cat2']))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4nEP5QQO04e","executionInfo":{"status":"ok","timestamp":1604247402205,"user_tz":480,"elapsed":5996,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","def df_shrink_dtypes(df, skip=[], obj2cat=True, int2uint=False):\n","    \"Return any possible smaller data types for DataFrame columns. Allows `object`->`category`, `int`->`uint`, and exclusion.\"\n","\n","    # 1: Build column filter and typemap\n","    excl_types, skip = {'category','datetime64[ns]','bool'}, set(skip)\n","\n","    typemap = {'int'   : [(np.dtype(x), np.iinfo(x).min, np.iinfo(x).max) for x in (np.int8, np.int16, np.int32, np.int64)],\n","               'uint'  : [(np.dtype(x), np.iinfo(x).min, np.iinfo(x).max) for x in (np.uint8, np.uint16, np.uint32, np.uint64)],\n","               'float' : [(np.dtype(x), np.finfo(x).min, np.finfo(x).max) for x in (np.float32, np.float64, np.longdouble)]\n","              }\n","    if obj2cat: typemap['object'] = 'category'  # User wants to categorify dtype('Object'), which may not always save space\n","    else:       excl_types.add('object')\n","\n","    new_dtypes = {}\n","    exclude = lambda dt: dt[1].name not in excl_types and dt[0] not in skip\n","\n","    for c, old_t in filter(exclude, df.dtypes.items()):\n","        t = next((v for k,v in typemap.items() if old_t.name.startswith(k)), None)\n","\n","        if isinstance(t, list): # Find the smallest type that fits\n","            if int2uint and t==typemap['int'] and df[c].min() >= 0: t=typemap['uint']\n","            new_t = next((r[0] for r in t if r[1]<=df[c].min() and r[2]>=df[c].max()), None)\n","            if new_t and new_t == old_t: new_t = None\n","        else: new_t = t if isinstance(t, str) else None\n","\n","        if new_t: new_dtypes[c] = new_t\n","    return new_dtypes"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKTDr0s7O04h","outputId":"c32d2808-58df-4b80-d427-dacac494ecd4"},"source":["show_doc(df_shrink_dtypes, title_level=3)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/markdown":"<h3 id=\"df_shrink_dtypes\" class=\"doc_header\"><code>df_shrink_dtypes</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n\n> <code>df_shrink_dtypes</code>(**`df`**, **`skip`**=*`[]`*, **`obj2cat`**=*`True`*, **`int2uint`**=*`False`*)\n\nReturn any possible smaller data types for DataFrame columns. Allows `object`->`category`, `int`->`uint`, and exclusion.","text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"vqC1BQtJO04p","executionInfo":{"status":"ok","timestamp":1604247713583,"user_tz":480,"elapsed":1817,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["df = pd.DataFrame({'i': [-100, 0, 100], 'f': [-100.0, 0.0, 100.0], 'e': [True, False, True],\n","                   'date':['2019-12-04','2019-11-29','2019-11-15',]})\n","dt = df_shrink_dtypes(df)\n","test_eq(df['i'].dtype, 'int64')\n","test_eq(dt['i'], 'int8')\n","\n","test_eq(df['f'].dtype, 'float64')\n","test_eq(dt['f'], 'float32')\n","\n","# Default ignore 'object' and 'boolean' columns\n","test_eq(df['date'].dtype, 'object')\n","test_eq(dt['date'], 'category')\n","\n","# Test categorifying 'object' type\n","dt2 = df_shrink_dtypes(df, obj2cat=False)\n","test_eq('date' not in dt2, True)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"AYPZ9nD8O04s","executionInfo":{"status":"ok","timestamp":1604247731441,"user_tz":480,"elapsed":2292,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","def df_shrink(df, skip=[], obj2cat=True, int2uint=False):\n","    \"Reduce DataFrame memory usage, by casting to smaller types returned by `df_shrink_dtypes()`.\"\n","    dt = df_shrink_dtypes(df, skip, obj2cat=obj2cat, int2uint=int2uint)\n","    return df.astype(dt)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"iTKYxeNyO04v","outputId":"7ffd6a0a-cf2a-406a-d029-0aeff2746eeb"},"source":["show_doc(df_shrink, title_level=3)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/markdown":"<h3 id=\"df_shrink\" class=\"doc_header\"><code>df_shrink</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n\n> <code>df_shrink</code>(**`df`**, **`skip`**=*`[]`*, **`obj2cat`**=*`True`*, **`int2uint`**=*`False`*)\n\nReduce DataFrame memory usage, by casting to smaller types returned by `df_shrink_dtypes()`.","text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"u7I8Qf85O04y"},"source":["`df_shrink(df)` attempts to make a DataFrame uses less memory, by fit numeric columns into smallest datatypes.  In addition:\n","\n"," * `boolean`, `category`, `datetime64[ns]` dtype columns are ignored.\n"," * 'object' type columns are categorified, which can save a lot of memory in large dataset.  It can be turned off by `obj2cat=False`.\n"," * `int2uint=True`, to fit `int` types to `uint` types, if all data in the column is >= 0.\n"," * columns can be excluded by name using `excl_cols=['col1','col2']`.\n","\n","To get only new column data types without actually casting a DataFrame,\n","use `df_shrink_dtypes()` with all the same parameters for `df_shrink()`."]},{"cell_type":"code","metadata":{"id":"r-yHDA3UO04z","executionInfo":{"status":"ok","timestamp":1604247962576,"user_tz":480,"elapsed":5515,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["df = pd.DataFrame({'i': [-100, 0, 100], 'f': [-100.0, 0.0, 100.0], 'u':[0, 10,254],\n","                  'date':['2019-12-04','2019-11-29','2019-11-15']})\n","df2 = df_shrink(df, skip=['date'])\n","\n","test_eq(df['i'].dtype=='int64' and df2['i'].dtype=='int8', True)\n","test_eq(df['f'].dtype=='float64' and df2['f'].dtype=='float32', True)\n","test_eq(df['u'].dtype=='int64' and df2['u'].dtype=='int16', True)\n","test_eq(df2['date'].dtype, 'object')\n","\n","test_eq(df2.memory_usage().sum() < df.memory_usage().sum(), True)\n","\n","# Test int => uint (when col.min() >= 0)\n","df3 = df_shrink(df, int2uint=True)\n","test_eq(df3['u'].dtype, 'uint8')  # int64 -> uint8 instead of int16\n","\n","# Test excluding columns\n","df4 = df_shrink(df, skip=['i','u'])\n","test_eq(df['i'].dtype, df4['i'].dtype)\n","test_eq(df4['u'].dtype, 'int64')"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O8TriCwzO041"},"source":["Here's an example using the `ADULT_SAMPLE` dataset:"]},{"cell_type":"code","metadata":{"id":"huQHCfH5O042","executionInfo":{"status":"ok","timestamp":1604247972341,"user_tz":480,"elapsed":5371,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"2ca9ca44-5282-4c8c-8c60-7fb4f0354784","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["path = untar_data(URLs.ADULT_SAMPLE)\n","df = pd.read_csv(path/'adult.csv')\n","new_df = df_shrink(df, int2uint=True)\n","print(f\"Memory usage: {df.memory_usage().sum()} --> {new_df.memory_usage().sum()}\")"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Memory usage: 3907448 --> 818665\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DtwND06cO044"},"source":["## Tabular -"]},{"cell_type":"code","metadata":{"id":"y4-nLl3aO045","executionInfo":{"status":"ok","timestamp":1604248241082,"user_tz":480,"elapsed":6084,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","class _TabIloc:\n","    \"Get/set rows by iloc and cols by name\"\n","    def __init__(self,to): self.to = to\n","    def __getitem__(self, idxs):\n","        df = self.to.items\n","        # If you have row and col then cols is replaced with integer index of the column\n","        # so this way we can use col names and row numbers\n","        if isinstance(idxs,tuple):\n","            rows,cols = idxs\n","            cols = df.columns.isin(cols) if is_listy(cols) else df.columns.get_loc(cols)\n","        else: rows,cols = idxs,slice(None)\n","        # It wraps it back up into a tabular object as well so if you index into a tab object\n","        # with iloc you get back a tab object as well. \n","        return self.to.new(df.iloc[rows, cols])"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"x92ajZXPU_Nh"},"source":["'''\n","Init signature: CollBase(*args, **kwargs)\n","Source:        \n","class CollBase:\n","    \"Base class for composing a list of `items`\"\n","    def __init__(self, items): self.items = items\n","    def __len__(self): return len(self.items)\n","    def __getitem__(self, k): return self.items[list(k) if isinstance(k,CollBase) else k]\n","    def __setitem__(self, k, v): self.items[list(k) if isinstance(k,CollBase) else k] = v\n","    def __delitem__(self, i): del(self.items[i])\n","    def __repr__(self): return self.items.__repr__()\n","    def __iter__(self): return self.items.__iter__()\n","File:           /usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\n","Type:           type\n","'''\n","CollBase??"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSXmaadUO048","executionInfo":{"status":"ok","timestamp":1604249721889,"user_tz":480,"elapsed":7572,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","class Tabular(CollBase, GetAttr, FilteredBase):\n","    \"A `DataFrame` wrapper that knows which cols are cont/cat/y, and returns rows in `__getitem__`\"\n","    '''\n","    A class that has all of the things in it that enables it to do all we want it to do\n","    Dataframe does NOT have all such info to build models. So categorical names, continuous names, processes \n","    used to process data, what dependent variable is y_names - typically one but could be more,\n","    so that is why we pass in those four things. (Multiple y_names examples is a regression problem\n","    of predicting x and y values or multi-label classification)\n","\n","    Make tabular object look a lot like dataframe - one way is to inherit from GetAttr - which means\n","    any unknown attributes passed down to _default property \n","    \n","    In df not convenient to index by row number and col by name - can do .iloc to get row by number and col by number\n","    can do .loc to get row by number or index and col y number or index BUT most common use case is row by number and \n","    col by name, SO redefined .iloc to use tabular iloc indexer \n","    '''\n","    _default,with_cont='procs',True\n","    def __init__(self, df, procs=None, cat_names=None, cont_names=None, y_names=None, y_block=None, splits=None,\n","                 do_setup=True, device=None, inplace=False, reduce_memory=True):\n","        if inplace and splits is not None and pd.options.mode.chained_assignment is not None:\n","            warn(\"Using inplace with splits will trigger a pandas error. Set `pd.options.mode.chained_assignment=None` to avoid it.\")\n","        if not inplace: df = df.copy()\n","        if reduce_memory: df = df_shrink(df)\n","        # below line is for rapids. Accessing individual items in df when df is in GPU (for rapids) is extra-ordinarily SLOW\n","        # so concatenate splits together if there are splits and index into the dataframe with that list and make the result\n","        # the dataframe that is used. So dataloaders then get continuous indices. \n","        if splits is not None: df = df.iloc[sum(splits, [])]\n","        self.dataloaders = delegates(self._dl_type.__init__)(self.dataloaders)\n","        # Tabular Inherits from CollBase which defines basic things you would expect to have in a collection\n","        # & implements them by compositions. If you pass in a list, len of the CollBase will be length of list \n","        # and so on. So by inheriting from collbase you can pass in df and so now we have self.items which is\n","        # going to be that dataframe. \n","        super().__init__(df)\n","\n","        self.y_names,self.device = L(y_names),device\n","        if y_block is None and self.y_names:\n","            # Make ys categorical if they're not numeric\n","            # Figures out whether y is type Category or Numeric \n","            # by making ys categorical if they are NOT numeric\n","            ys = df[self.y_names]\n","            if len(ys.select_dtypes(include='number').columns)!=len(ys.columns): y_block = CategoryBlock()\n","            else: y_block = RegressionBlock()\n","        if y_block is not None and do_setup:\n","            if callable(y_block): y_block = y_block()\n","            procs = L(procs) + y_block.type_tfms\n","        # the procs are transforms and we make them Pipelines\n","        # Also, unless like for Tfmdlists, TfmdDL etc we do NOT apply procs lazily but ahead of time\n","        # Reasons: unlike opening an image, does not take whole lot of time to process number of rows\n","        # most tabular stuff is also designed to work quickly on lots of rows so faster if you do the\n","        # procs ahead of time, most proces is not data augmentation but just once applied data cleaning\n","        # type of stuff.\n","        # Still pipeline of transforms though \n","        self.cat_names,self.cont_names,self.procs = L(cat_names),L(cont_names),Pipeline(procs)\n","        self.split = len(df) if splits is None else len(splits[0])\n","        if do_setup: self.setup()\n","\n","    def new(self, df):\n","        return type(self)(df, do_setup=False, reduce_memory=False, y_block=TransformBlock(),\n","                          **attrdict(self, 'procs','cat_names','cont_names','y_names', 'device'))\n","\n","    def subset(self, i): return self.new(self.items[slice(0,self.split) if i==0 else slice(self.split,len(self))])\n","    def copy(self): self.items = self.items.copy(); return self\n","    def decode(self): return self.procs.decode(self)\n","    def decode_row(self, row): return self.new(pd.DataFrame(row).T).decode().items.iloc[0]\n","    def show(self, max_n=10, **kwargs): display_df(self.new(self.all_cols[:max_n]).decode().items)\n","    def setup(self): self.procs.setup(self)\n","    def process(self): self.procs(self)\n","    def loc(self): return self.items.loc\n","    def iloc(self): return _TabIloc(self)\n","    def targ(self): return self.items[self.y_names]\n","    def x_names (self): return self.cat_names + self.cont_names\n","    def n_subsets(self): return 2\n","    def y(self): return self[self.y_names[0]]\n","    def new_empty(self): return self.new(pd.DataFrame({}, columns=self.items.columns))\n","    def to_device(self, d=None):\n","        self.device = d\n","        return self\n","\n","    def all_col_names (self):\n","        ys = [n for n in self.y_names if n in self.items.columns]\n","        # Aside: Adding a none value works since each is an L \n","        # will NOT work if ordinary list\n","        return self.x_names + self.y_names if len(ys) == len(self.y_names) else self.x_names\n","\n","# Below is just alternate syntax to create a number of properties instead of saying @property before\n","# each of these. So it creates these properties.\n","properties(Tabular,'loc','iloc','targ','all_col_names','n_subsets','x_names','y')"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lEZ5-dvRO04_"},"source":["* `df`: A `DataFrame` of your data\n","* `cat_names`: Your categorical `x` variables\n","* `cont_names`: Your continuous `x` variables\n","* `y_names`: Your dependent `y` variables\n","  * Note: Mixed y's such as Regression and Classification is not currently supported, however multiple regression or classification outputs is\n","* `y_block`: How to sub-categorize the type of `y_names` (`CategoryBlock` or `RegressionBlock`)\n","* `splits`: How to split your data\n","* `do_setup`: A parameter for if `Tabular` will run the data through the `procs` upon initialization\n","* `device`: `cuda` or `cpu`\n","* `inplace`: If `True`, `Tabular` will not keep a separate copy of your original `DataFrame` in memory. You should ensure `pd.options.mode.chained_assignment` is `None` before setting this\n","* `reduce_memory`: `fastai` will attempt to reduce the overall memory usage by the inputted `DataFrame` with `df_shrink`"]},{"cell_type":"code","metadata":{"id":"ZMn2QyReWE_b"},"source":["'''\n","Signature: properties(cls, *ps)\n","Source:   \n","def properties(cls, *ps):\n","    \"Change attrs in `cls` with names in `ps` to properties\"\n","    for p in ps: setattr(cls,p,property(getattr(cls,p)))\n","File:      /usr/local/lib/python3.6/dist-packages/fastcore/utils.py\n","Type:      function\n","'''\n","properties??"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HiKZlBQqO05A","executionInfo":{"status":"ok","timestamp":1604249746493,"user_tz":480,"elapsed":10275,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","class TabularPandas(Tabular):\n","    \"A `Tabular` object with transforms\"\n","    def transform(self, cols, f, all_col=True):\n","        if not all_col: cols = [c for c in cols if c in self.items.columns]\n","        if len(cols) > 0: self[cols] = self[cols].transform(f)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"RcAeWzWFO05D","executionInfo":{"status":"ok","timestamp":1604249759839,"user_tz":480,"elapsed":5266,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","def _add_prop(cls, nm): \n","    @property\n","    # read version of property which grabs 'nm'_names so \n","    # cat_names, cont_names etc and accesses into that df \n","    # with the list of columns\n","    def f(o): return o[list(getattr(o,nm+'_names'))]\n","    @f.setter\n","    # setter helps to set 'nm'_names to provided value v\n","    #\n","    def fset(o, v): o[getattr(o,nm+'_names')] = v\n","    setattr(cls, nm+'s', f)\n","    setattr(cls, nm+'s', fset)\n","\n","_add_prop(Tabular, 'cat')\n","_add_prop(Tabular, 'cont')\n","_add_prop(Tabular, 'y')\n","_add_prop(Tabular, 'x')\n","_add_prop(Tabular, 'all_col')"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"phmB_vOxO05G","executionInfo":{"status":"ok","timestamp":1604249846713,"user_tz":480,"elapsed":7043,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["# A df with 2 cols\n","df = pd.DataFrame({'a':[0,1,2,0,2], 'b':[0,0,0,0,1]})\n","# Create a Tabular object passing in the df and saying cat_names = 'a'\n","to = TabularPandas(df, cat_names='a')\n","# test that this pickles ok\n","t = pickle.loads(pickle.dumps(to))\n","# check that t's items and tabular object items are same\n","test_eq(t.items,to.items)\n","# \n","# Coz Tabular object 'to' has only one col 'a' mentioned even though\n","# df has 'a' and 'b', all_cols of 'to' only has 'a'\n","# all_cols means all columns cont & cat & dep vars\n","test_eq(to.all_cols,to[['a']])\n","# check whether to.show() works to show col 'a'"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"G9j0GCCwXKY8","executionInfo":{"status":"ok","timestamp":1604250043811,"user_tz":480,"elapsed":8207,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"d8dc328d-eb17-4eaf-d2b5-b238becb167c","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["to.show()"],"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"uxyEszi6O05J","executionInfo":{"status":"ok","timestamp":1604250279811,"user_tz":480,"elapsed":2941,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","class TabularProc(InplaceTransform):\n","    \"Base class to write a non-lazy tabular processor for dataframes\"\n","    # Tabular processes are just transforms - specifically InplaceTransforms\n","    # For tabular data we would NOT like to create lots of copies of it\n","    # InplaceTransform -> call it and then return the original thing \n","    # Processes goal is to change the data that is stored and InplaceTransform helps\n","    # by returning what you started with.\n","    # So TabularProc is just a transform that returns itself when you call it and when\n","    # you set it up, just does normal setup but also calls __call__ which is the\n","    # self(items.items ....) line. WHY? Look at example\n","    # So TabularProc overrides setup and it is a transform that when you set it up it \n","    # also immediately calls it straightaway.\n","    def setup(self, items=None, train_setup=False): #TODO: properly deal with train_setup\n","        super().setup(getattr(items,'train',items), train_setup=False)\n","        # Procs are called as soon as data is available\n","        # Below step is explained further (see Categorify eg below). \n","        # It is running encodes after running setup. Encodes (a call) actually\n","        # converts the categorical cols into ints using vocab generated in setup\n","        return self(items.items if isinstance(items,Datasets) else items)\n","\n","    @property\n","    def name(self): return f\"{super().name} -- {getattr(self,'__stored_args__',{})}\""],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ByxfVrxsAMea"},"source":["map is a pandas method. can pass it a function, which is going to be super slow but you can pass it a dict and that will map from keys to values in the dict "]},{"cell_type":"code","metadata":{"id":"CeNywEyPO05L","executionInfo":{"status":"ok","timestamp":1604250353806,"user_tz":480,"elapsed":2760,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","def _apply_cats (voc, add, c):\n","    if not is_categorical_dtype(c):\n","        return pd.Categorical(c, categories=voc[c.name][add:]).codes+add\n","    return c.cat.codes+add #if is_categorical_dtype(c) else c.map(voc[c.name].o2i)\n","def _decode_cats(voc, c): return c.map(dict(enumerate(voc[c.name].items)))"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"A4Swo6tt5rqC"},"source":["'''\n","Init signature: CategoryMap(*args, **kwargs)\n","Source:        \n","class CategoryMap(CollBase):\n","    \"Collection of categories with the reverse mapping in `o2i`\"\n","    def __init__(self, col, sort=True, add_na=False, strict=False):\n","        if is_categorical_dtype(col):\n","            items = L(col.cat.categories, use_list=True)\n","            #Remove non-used categories while keeping order\n","            if strict: items = L(o for o in items if o in col.unique())\n","        else:\n","            if not hasattr(col,'unique'): col = L(col, use_list=True)\n","            # `o==o` is the generalized definition of non-NaN used by Pandas\n","            items = L(o for o in col.unique() if o==o)\n","            if sort: items = items.sorted()\n","        self.items = '#na#' + items if add_na else items\n","        self.o2i = defaultdict(int, self.items.val2idx()) if add_na else dict(self.items.val2idx())\n","\n","    def map_objs(self,objs):\n","        \"Map `objs` to IDs\"\n","        return L(self.o2i[o] for o in objs)\n","\n","    def map_ids(self,ids):\n","        \"Map `ids` to objects in vocab\"\n","        return L(self.items[o] for o in ids)\n","\n","    def __eq__(self,b): return all_equal(b,self)\n","File:           /usr/local/lib/python3.6/dist-packages/fastai/data/transforms.py\n","Type:           type\n","'''\n","CategoryMap??"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D6D5JUd_O05O","executionInfo":{"status":"ok","timestamp":1604250775266,"user_tz":480,"elapsed":2444,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","class Categorify(TabularProc):\n","    \"Transform the categorical variables to something similar to `pd.Categorical`\"\n","    # Similar transform to categorized we have seen for dependent variables like image\n","    # specification but Categorify is for Tabular objects (to)\n","    order = 1\n","    # Setups creates a CategoryMap as a mapping from int numbers as its vocab to \n","    # to a string map - that is what a Category map is, so it goes through all\n","    # Categorical columns, go into the dataframe using .iloc for each of those cols\n","    # and create a CategoryMap for that col.\n","    # So self.classes is therefore going to be a dict that goes from col names to the\n","    # vocab for that categorical column. \n","    # So setup sets up the metadata - its vocab.\n","    def setups(self, to):\n","        store_attr(classes={n:CategoryMap(to.iloc[:,n].items, add_na=(n in to.cat_names)) for n in to.cat_names})\n","\n","    # Encodes takes the categorical cols and converts them into ints using the vocab created in setups.\n","    # Needs to be two separate things coz at inference time, you do not want to run setups, you just run encodes.\n","    # At trng time do BOTH.\n","\n","    # pass in to a transform the col names and a function _apply_cats UNLESS you have a pandas Categorical col \n","    # in which case pandas has done the coding for you so you just use the codes and add\n","\n","    # How does function _apply_cats get applied to each of col in cat_names - coz it uses to.transform\n","    # using TabularPandas (see above) for pandas the cols become the transformed version of the columns.\n","    # coz pandas has a .transform method for Series which is for each column.\n","    def encodes(self, to): to.transform(to.cat_names, partial(_apply_cats, self.classes, 1))\n","    def decodes(self, to): to.transform(to.cat_names, partial(_decode_cats, self.classes))\n","    def __getitem__(self,k): return self.classes[k]"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"qVIk40QPO05V","executionInfo":{"status":"ok","timestamp":1604250787054,"user_tz":480,"elapsed":3238,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#export\n","@Categorize\n","def setups(self, to:Tabular):\n","    if len(to.y_names) > 0:\n","        if self.vocab is None:\n","            self.vocab = CategoryMap(getattr(to, 'train', to).iloc[:,to.y_names[0]].items, strict=True)\n","        else:\n","            self.vocab = CategoryMap(self.vocab, sort=False, add_na=self.add_na)\n","        self.c = len(self.vocab)\n","    return self(to)\n","\n","@Categorize\n","def encodes(self, to:Tabular):\n","    to.transform(to.y_names, partial(_apply_cats, {n: self.vocab for n in to.y_names}, 0), all_col=False)\n","    return to\n","\n","@Categorize\n","def decodes(self, to:Tabular):\n","    to.transform(to.y_names, partial(_decode_cats, {n: self.vocab for n in to.y_names}), all_col=False)\n","    return to"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"U4Zj4KLOO05X","outputId":"bc1bf7d5-9b19-49d2-fa69-b32c80dba264"},"source":["show_doc(Categorify, title_level=3)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/markdown":"<h3 id=\"Categorify\" class=\"doc_header\"><code>class</code> <code>Categorify</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n\n> <code>Categorify</code>(**`enc`**=*`None`*, **`dec`**=*`None`*, **`split_idx`**=*`None`*, **`order`**=*`None`*) :: [`TabularProc`](/tabular.core.html#TabularProc)\n\nTransform the categorical variables to something similar to `pd.Categorical`","text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"aN5rcKgCO05a","executionInfo":{"status":"ok","timestamp":1604251416506,"user_tz":480,"elapsed":6511,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"4cfab1bb-6b9a-47ed-9b9e-21f640e42a24","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df = pd.DataFrame({'a':[0,1,2,0,2]})\n","# Create a tabular object passing in a dataframe and any procs we wish to run and\n","# cat_names (ie col names which are categories) that we wish to run categorify on.\n","\n","# Here we added a Categorify transform - we have not instantiated it - we just pass\n","# in the type, Pipeline is going to instantiate it for us - Pipeline always instantiates\n","# the types for you if you do not instantiate them\n","to = TabularPandas(df, Categorify, 'a')\n","# Once to created we check that the categorify procs does what we expect for col 'a'\n","# call setup, then encodes, \n","\n","# Recall that to.procs is of type Pipeline and also recall that if an attr is NOT found\n","# in any transforms it will continue to look for that attr in other transforms in the\n","# Pipeline which is what we want. The attribute is NOT added but uses Getattr to get\n","# the attribute\n","# Here it will look for a transform with type categorify and it converts to snakecase\n","# ASIDE: In V2 callbacks get automatically added as attributes.\n","\n","# To find the vocab, We grab the procs out of our tabular object and ask for the\n","# categorify transform. Categorify has a __getitem__ which returns the vocab for \n","# that column\n","cat = to.procs.categorify\n","# can see that whenever we create a categorify column, we add a '#na#' at the start\n","# (Same as in fastai-V1). Done so that in future if you get value outside of your vocab\n","# it will be '#na#' and hence what you see below. So below is the vocab for col 'a'\n","test_eq(cat['a'], ['#na#',0,1,2])\n","# It uses a defaultdict for the reverse dict o2i and so if item in testset that is not\n","# seen in training set (hence not in vocab) mapped to 0 ie #na# during test/inference\n","test_eq(to['a'], [1,2,3,1,3])\n","to.show()"],"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"PQ_qBC8CBtVh","executionInfo":{"status":"ok","timestamp":1604212745673,"user_tz":420,"elapsed":1289,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"7f9a721d-81ed-4056-b32e-ca801940fca0","colab":{"base_uri":"https://localhost:8080/"}},"source":["# skr adds\n","print(type(to.procs)) # Pipeline\n","print(type(cat['a'])) # CategoryMap\n","print(cat['a'].items) # same as vocab\n","print(cat['a'].o2i) # reverse dict"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'fastcore.transform.Pipeline'>\n","<class 'fastai.data.transforms.CategoryMap'>\n","['#na#', 0, 1, 2]\n","defaultdict(<class 'int'>, {'#na#': 0, 0: 1, 1: 2, 2: 3})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RP8Gt70PO05d","executionInfo":{"status":"ok","timestamp":1604251975826,"user_tz":480,"elapsed":2558,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["# say test set or inference\n","# create a new to for the testset with the same metadata & procs\n","# as we had before, so same vocab, same cont, cat vars, \n","# way to do that is to start with same tabular object as before and\n","# pass in a new dataframe - here df1 passed in to tabular object to\n","# and we get back to1 a new tabular object with same metadata, vocab\n","# but with new data.\n","df1 = pd.DataFrame({'a':[1,0,3,-1,2]})\n","to1 = to.new(df1)\n","# But we do NOT want to call setup though, so we just call process\n","# which only calls procs (it is a pipeline so can be treated as a function)\n","to1.process()\n","# Have a couple of items -1 and 3 not in vocab\n","#Values that weren't in the training df are sent to 0 (na)\n","test_eq(to1['a'], [2,1,0,0,3])\n","# if you call decode you end up with same data you started with but for\n","# the two #na#s. \n","to2 = cat.decode(to1)\n","test_eq(to2['a'], [1,0,'#na#','#na#',2])"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FYqI3OVxQ0ql"},"source":["Imp: Decoding in fastai in general does NOT always mean you get back what you started with. Some cases like normaization you get back what you started with but with some things like Categorify it won't be."]},{"cell_type":"code","metadata":{"id":"zO6ooMpGO05g","executionInfo":{"status":"ok","timestamp":1604252447971,"user_tz":480,"elapsed":2654,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#test with splits\n","\n","# not necessary to pass in type name, can instantiate ourselves\n","# as in cat is instance of Categorify. Then no need to pull out the\n","# cat as to.procs.categorify\n","cat = Categorify()\n","df = pd.DataFrame({'a':[0,1,2,3,2]})\n","# splits says first three elems of 'a' are in training set and last 2 in val set\n","# so elem 3 in 'a' is NOT in training set. So value 3 should NOT be part of vocab\n","# \n","# We pass in splits as list of lists of indices to creation of tabular object.\n","# \n","to = TabularPandas(df, cat, 'a', splits=[[0,1,2],[3,4]])\n","# vocab has only #na# and 0, 1, 2 and NO 3\n","test_eq(cat['a'], ['#na#',0,1,2])\n","# Check that vocab does not include value 3 - it does NOT\n","test_eq(to['a'], [1,2,3,0,3])"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"IShx1lzjTbnT","executionInfo":{"status":"ok","timestamp":1604252478709,"user_tz":480,"elapsed":7616,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"ff8b620a-b138-413e-a652-39c2668c2972","colab":{"base_uri":"https://localhost:8080/"}},"source":["# skr adds - check dataset\n","print(to.train)\n","# Notice that the values for a are indices into the vocab\n","# ie indices 1, 2, 3 which point to values 0, 1, 2\n","print()\n","print(to.valid)\n","# Indices 0 and 3 into vocab so values #na# and 2."],"execution_count":36,"outputs":[{"output_type":"stream","text":["   a\n","0  1\n","1  2\n","2  3\n","\n","   a\n","3  0\n","4  3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"va-NL_S_cORt","executionInfo":{"status":"ok","timestamp":1604252490298,"user_tz":480,"elapsed":5275,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"40dc3040-f43e-4427-8e42-8ea8b8b37c44","colab":{"base_uri":"https://localhost:8080/"}},"source":["to.n_subsets"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"3c1YfPp7O05i","executionInfo":{"status":"ok","timestamp":1604252587034,"user_tz":480,"elapsed":1978,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["# Other way to use Categorify \n","# Create categorical col in Pandas itself, one reason to do this is defining not just categories\n","# but their order as well. Pandas is also efficient at dealing with categories.\n","df = pd.DataFrame({'a':pd.Categorical(['M','H','L','M'], categories=['H','M','L'], ordered=True)})\n","# Now when we use Categorify as before we get same result EXCEPT\n","to = TabularPandas(df, Categorify, 'a')\n","cat = to.procs.categorify\n","# The categorical processor ensures categories in right order and matched in that way \n","# and pssibly more efficiently since it is using Pandas internal _cat_codes code \n","test_eq(cat['a'], ['#na#','H','M','L'])\n","test_eq(to.items.a, [2,1,3,2])\n","to2 = cat.decode(to)\n","test_eq(to2['a'], ['M','H','L','M'])"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"vK-gpktoO05l","executionInfo":{"status":"ok","timestamp":1604252939627,"user_tz":480,"elapsed":2139,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}}},"source":["#test with targets\n","cat = Categorify()\n","df = pd.DataFrame({'a':[0,1,2,3,2], 'b': ['a', 'b', 'a', 'b', 'b']})\n","to = TabularPandas(df, cat, 'a', splits=[[0,1,2],[3,4]], y_names='b')\n","test_eq(to.vocab, ['a', 'b'])\n","test_eq(to['a'], [1, 2, 3, 0, 3])\n","test_eq(to['b'], [0,1,0,1,1])\n","to2 = to.procs.decode(to)\n","test_eq(to2['b'], ['a', 'b', 'a', 'b', 'b'])"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"ykyUxMTsO05o"},"source":["# duplicate?\n","cat = Categorify()\n","df = pd.DataFrame({'a':[0,1,2,3,2], 'b': ['a', 'b', 'a', 'b', 'b']})\n","to = TabularPandas(df, cat, 'a', splits=[[0,1,2],[3,4]], y_names='b')\n","test_eq(to.vocab, ['a', 'b'])\n","test_eq(to['b'], [0,1,0,1,1])\n","to2 = to.procs.decode(to)\n","test_eq(to2['b'], ['a', 'b', 'a', 'b', 'b'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JhxxNzrVO05q"},"source":["#test with targets and train\n","cat = Categorify()\n","df = pd.DataFrame({'a':[0,1,2,3,2], 'b': ['a', 'b', 'a', 'c', 'b']})\n","to = TabularPandas(df, cat, 'a', splits=[[0,1,2],[3,4]], y_names='b')\n","test_eq(to.vocab, ['a', 'b'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Co8SBuh2O05t"},"source":["#export\n","@Normalize\n","def setups(self, to:Tabular):\n","    # This says if to has train attr then make the to means be the\n","    # mean of the to train otherwise mean of to. Same for std.\n","    # So to can have a train and valid or not and the setup code\n","    # should work for both conditions and return right type of object\n","    # Notice that we are doing this only to the continuous vars in the\n","    # to. \n","\n","    # We are getting below the means and stds for all the cols of the continuous vars\n","    # in the to - akin to df.mean()\n","    store_attr(means=dict(getattr(to, 'train', to).conts.mean()),\n","               stds=dict(getattr(to, 'train', to).conts.std(ddof=0)+1e-7))\n","    return self(to)\n","\n","@Normalize\n","def encodes(self, to:Tabular):\n","    # Applying to all cont cols in to at once\n","    to.conts = (to.conts-self.means) / self.stds\n","    return to\n","\n","@Normalize\n","def decodes(self, to:Tabular):\n","    to.conts = (to.conts*self.stds ) + self.means\n","    return to"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oEw0gQeRO05w"},"source":["norm = Normalize()\n","df = pd.DataFrame({'a':[0,1,2,3,4]})\n","to = TabularPandas(df, norm, cont_names='a')\n","x = np.array([0,1,2,3,4])\n","m,s = x.mean(),x.std()\n","test_eq(norm.means['a'], m)\n","test_close(norm.stds['a'], s)\n","test_close(to['a'].values, (x-m)/s)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hezHg5EO052"},"source":["df1 = pd.DataFrame({'a':[5,6,7]})\n","#provide df1 to create a new to using to\n","to1 = to.new(df1)\n","#only process no setup\n","to1.process()\n","# check normalize is appplied using to's m and s\n","test_close(to1['a'].values, (np.array([5,6,7])-m)/s)\n","to2 = norm.decode(to1)\n","# decode gets back orig values\n","test_close(to2['a'].values, [5,6,7])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jlbH2Lg0O054"},"source":["# using splits for training and validation\n","norm = Normalize()\n","df = pd.DataFrame({'a':[0,1,2,3,4]})\n","to = TabularPandas(df, norm, cont_names='a', splits=[[0,1,2],[3,4]])\n","# so m and s are of training set of to \n","x = np.array([0,1,2])\n","m,s = x.mean(),x.std()\n","test_eq(norm.means['a'], m)\n","test_close(norm.stds['a'], s)\n","test_close(to['a'].values, (np.array([0,1,2,3,4])-m)/s)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qu7vQN5IO057"},"source":["#export\n","class FillStrategy:\n","    \"Namespace containing the various filling strategies.\"\n","    # Class containing 3 diff methods, \n","    def median  (c,fill): return c.median()\n","    def constant(c,fill): return fill\n","    def mode    (c,fill): return c.dropna().value_counts().idxmax()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pg27-JulO05_"},"source":["Currently, filling with the `median`, a `constant`, and the `mode` are supported."]},{"cell_type":"code","metadata":{"id":"aG0WgnZWO06A"},"source":["#export\n","class FillMissing(TabularProc):\n","    \"Fill the missing values in continuous columns.\"\n","    def __init__(self, fill_strategy=FillStrategy.median, add_col=True, fill_vals=None):\n","        if fill_vals is None: fill_vals = defaultdict(int)\n","        store_attr()\n","\n","    def setups(self, dsets):\n","        # check for any missing values in every cont col \n","        missing = pd.isnull(dsets.conts).any()\n","        # if any missing create a na_dict where the col with missing values appears as\n","        # col name in na_dict and the value of the missing value will depend on the\n","        # fill_strategy you ask for = median, mode, const, passing in the col, and fill value\n","        store_attr(na_dict={n:self.fill_strategy(dsets[n], self.fill_vals[n])\n","                            for n in missing[missing].keys()})\n","        self.fill_strategy = self.fill_strategy.__name__\n","\n","    def encodes(self, to):\n","        # when encodes do 2 things: first use pandas fillna to fill whatever value we \n","        # put in as fill value in the dict for that col, and do it in place.\n","        # Second: if we ask to add a col to indicate which rows have missing vals filled in\n","        # then we add a col with same name and _na at the end which is of type boolean\n","        # and True if that value is missing and \n","        missing = pd.isnull(to.conts)\n","        for n in missing.any()[missing.any()].keys():\n","            assert n in self.na_dict, f\"nan values in `{n}` but not in setup training set\"\n","        for n in self.na_dict.keys():\n","            to[n].fillna(self.na_dict[n], inplace=True)\n","            if self.add_col:\n","                to.loc[:,n+'_na'] = missing[n]\n","                if n+'_na' not in to.cat_names: to.cat_names.append(n+'_na')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T5QXqPVJO06D","outputId":"45947a95-fbd2-49a8-a060-817ed47f577c"},"source":["show_doc(FillMissing, title_level=3)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/markdown":"<h3 id=\"FillMissing\" class=\"doc_header\"><code>class</code> <code>FillMissing</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n\n> <code>FillMissing</code>(**`fill_strategy`**=*`median`*, **`add_col`**=*`True`*, **`fill_vals`**=*`None`*) :: [`TabularProc`](/tabular.core.html#TabularProc)\n\nFill the missing values in continuous columns.","text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"rbLEQjx7O06G"},"source":["# Creating 3 different processes with 3 diff fill strategies \n","fill1,fill2,fill3 = (FillMissing(fill_strategy=s) \n","                     for s in [FillStrategy.median, FillStrategy.constant, FillStrategy.mode])\n","# df with missing value\n","df = pd.DataFrame({'a':[0,1,np.nan,1,2,3,4]})\n","df1 = df.copy(); df2 = df.copy()\n","# tos with 3 diff processes\n","tos = (TabularPandas(df, fill1, cont_names='a'),\n","       TabularPandas(df1, fill2, cont_names='a'),\n","       TabularPandas(df2, fill3, cont_names='a'))\n","# make sure that na_dict for 'a' col has appropriate fill value\n","# of median, constant or mode value of col 'a'. \n","test_eq(fill1.na_dict, {'a': 1.5})\n","test_eq(fill2.na_dict, {'a': 0})\n","test_eq(fill3.na_dict, {'a': 1.0})\n","\n","# check that to has cat_names added 'a_na'\n","# NOT enough to add to df, also need to add to cat_names of tabular object.\n","for t in tos: test_eq(t.cat_names, ['a_na'])\n","\n","for to_,v in zip(tos, [1.5, 0., 1.]):\n","    test_eq(to_['a'].values, np.array([0, 1, v, 1, 2, 3, 4]))\n","    test_eq(to_['a_na'].values, np.array([0, 0, 1, 0, 0, 0, 0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"07MczxXcO06J"},"source":["fill = FillMissing() \n","df = pd.DataFrame({'a':[0,1,np.nan,1,2,3,4], 'b': [0,1,2,3,4,5,6]})\n","to = TabularPandas(df, fill, cont_names=['a', 'b'])\n","test_eq(fill.na_dict, {'a': 1.5})\n","test_eq(to.cat_names, ['a_na'])\n","test_eq(to['a'].values, np.array([0, 1, 1.5, 1, 2, 3, 4]))\n","test_eq(to['a_na'].values, np.array([0, 0, 1, 0, 0, 0, 0]))\n","test_eq(to['b'].values, np.array([0,1,2,3,4,5,6]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EfctiTUzO06L"},"source":["## TabularPandas Pipelines -"]},{"cell_type":"code","metadata":{"id":"dDf2SUAqO06L"},"source":["procs = [Normalize, Categorify, FillMissing, noop]\n","# a col cat b col cont\n","df = pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,1,np.nan,1,2,3,4]})\n","to = TabularPandas(df, procs, cat_names='a', cont_names='b')\n","\n","# The procs will only work on cols of specific types \n","# eg normalize only on cont cols, categorify only on cat cols\n","# ALSO: for cat cols we also categorize Dependent vars but for \n","# normalize we don't normalize dependent vars but typically do\n","# a sigmoid in the model or something like that.\n","\n","#Test setup and apply on df_main\n","test_eq(to.cat_names, ['a', 'b_na'])\n","test_eq(to['a'], [1,2,3,2,2,3,1])\n","test_eq(to['b_na'], [1,1,2,1,1,1,1])\n","x = np.array([0,1,1.5,1,2,3,4])\n","m,s = x.mean(),x.std()\n","test_close(to['b'].values, (x-m)/s)\n","test_eq(to.classes, {'a': ['#na#',0,1,2], 'b_na': ['#na#',False,True]})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jdc76PYhO06O"},"source":["#Test apply on y_names\n","df = pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,1,np.nan,1,2,3,4], 'c': ['b','a','b','a','a','b','a']})\n","to = TabularPandas(df, procs, 'a', 'b', y_names='c')\n","\n","test_eq(to.cat_names, ['a', 'b_na'])\n","test_eq(to['a'], [1,2,3,2,2,3,1])\n","test_eq(to['b_na'], [1,1,2,1,1,1,1])\n","test_eq(to['c'], [1,0,1,0,0,1,0])\n","x = np.array([0,1,1.5,1,2,3,4])\n","m,s = x.mean(),x.std()\n","test_close(to['b'].values, (x-m)/s)\n","test_eq(to.classes, {'a': ['#na#',0,1,2], 'b_na': ['#na#',False,True]})\n","test_eq(to.vocab, ['a','b'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-3Je4xMO06S"},"source":["df = pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,1,np.nan,1,2,3,4], 'c': ['b','a','b','a','a','b','a']})\n","to = TabularPandas(df, procs, 'a', 'b', y_names='c')\n","\n","test_eq(to.cat_names, ['a', 'b_na'])\n","test_eq(to['a'], [1,2,3,2,2,3,1])\n","test_eq(df.a.dtype,int)\n","test_eq(to['b_na'], [1,1,2,1,1,1,1])\n","test_eq(to['c'], [1,0,1,0,0,1,0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LNMdeNKWO06U"},"source":["df = pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,np.nan,1,1,2,3,4], 'c': ['b','a','b','a','a','b','a']})\n","to = TabularPandas(df, procs, cat_names='a', cont_names='b', y_names='c', splits=[[0,1,4,6], [2,3,5]])\n","\n","test_eq(to.cat_names, ['a', 'b_na'])\n","# coz of split there is no 2 in vocab of a, hence 0,2,0 last \n","test_eq(to['a'], [1,2,2,1,0,2,0])\n","test_eq(df.a.dtype,int)\n","test_eq(to['b_na'], [1,2,1,1,1,1,1])\n","test_eq(to['c'], [1,0,0,0,1,0,1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQH-3NB9O06Z"},"source":["#export\n","def _maybe_expand(o): return o[:,None] if o.ndim==1 else o"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D6urr8HE2asA"},"source":["To model we need Tensors - one for cat vars, one for cont vars and one for dep vars. The cont and cat are different data types and we cannot put them all in the same tensor since (in order to be in one tensor they all have to be same data type). "]},{"cell_type":"code","metadata":{"id":"AQbqAhfeO06c"},"source":["#export\n","class ReadTabBatch(ItemTransform):\n","    # Now we create a typical normal lazy transform which gets applied \n","    # as we are getting our batches. \n","\n","    # tabular object we are transforming. \n","    def __init__(self, to): self.to = to\n","\n","    def encodes(self, to):\n","        # grab cat vars make tensors out of them turn them to long\n","        if not to.with_cont: res = (tensor(to.cats).long(),)\n","        # grab cont make them tensor then floats \n","        # also make those two things a tuple of those 2 things\n","        # These are our independent vars\n","        else: res = (tensor(to.cats).long(),tensor(to.conts).float())\n","        # Dependent var turned into a long/float\n","        ys = [n for n in to.y_names if n in to.items.columns]\n","        if len(ys) == len(to.y_names): res = res + (tensor(to.targ),)\n","        if to.device is not None: res = to_device(res, to.device)\n","        return res\n","\n","    def decodes(self, o):\n","        o = [_maybe_expand(o_) for o_ in to_np(o) if o_.size != 0]\n","        vals = np.concatenate(o, axis=1)\n","        try: df = pd.DataFrame(vals, columns=self.to.all_col_names)\n","        except: df = pd.DataFrame(vals, columns=self.to.x_names)\n","        to = self.to.new(df)\n","        return to"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aCAqbTgJO06e"},"source":["#export\n","@typedispatch\n","def show_batch(x: Tabular, y, its, max_n=10, ctxs=None):\n","    x.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"falhhQN5O06h"},"source":["from torch.utils.data.dataloader import _MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter,_DatasetKind"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZXCbNCsO06j"},"source":["_loaders = (_MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jcXrhrlJO06n"},"source":["#export\n","@delegates()\n","class TabDataLoader(TfmdDL):\n","    \"A transformed `DataLoader` for Tabular data\"\n","    #\n","    # We want to do everything a batch at a time, so especially for rapids stuff we don't want\n","    # to pull out individual rows and collect them later, everything done by grabbing whole batch \n","    # at a time, That is why we replace do_item - the thing that grabs a single item, for collation\n","    # we replace with noops. \n","    do_item = noops\n","    def __init__(self, dataset, bs=16, shuffle=False, after_batch=None, num_workers=0, **kwargs):\n","        # Tabular Data Loader is a transform data loader where we know that any after_batch callback\n","        # you aksed for we also need to add in ReadTabBatch so that is automatically added to the\n","        # Transforms for you. \n","        if after_batch is None: after_batch = L(TransformBlock().batch_tfms)+ReadTabBatch(dataset)\n","        super().__init__(dataset, bs=bs, shuffle=shuffle, after_batch=after_batch, num_workers=num_workers, **kwargs)\n","    # Also replace below create_batch which collates things into a batch with something that grabs all of the samples\n","    # in a batch. directly from the to using iloc. \n","    # So when rapids got 16X speedup they wrote own version of this type of code. This is also one of the reasons\n","    # to replace PyTorch Dataloader to make this kind of thing easy to do so creating a batch at a time data loader\n","    # is just 7ish lines of code. \n","    def create_batch(self, b): return self.dataset.iloc[b]\n","\n","TabularPandas._dl_type = TabDataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DK8YLcZ6O06p"},"source":["## Integration example\n","\n","For a more in-depth explanation, see the [tabular tutorial](http://docs.fast.ai/tutorial.tabular)"]},{"cell_type":"code","metadata":{"id":"KS32Sdt8O06p","executionInfo":{"status":"ok","timestamp":1604215336707,"user_tz":420,"elapsed":1051,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"ad6304b5-68ef-481f-b4c0-d1af22847de6","colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["path = untar_data(URLs.ADULT_SAMPLE)\n","df = pd.read_csv(path/'adult.csv')\n","df_main,df_test = df.iloc[:10000].copy(),df.iloc[10000:].copy()\n","df_test.drop('salary', axis=1, inplace=True)\n","df_main.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>workclass</th>\n","      <th>fnlwgt</th>\n","      <th>education</th>\n","      <th>education-num</th>\n","      <th>marital-status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>sex</th>\n","      <th>capital-gain</th>\n","      <th>capital-loss</th>\n","      <th>hours-per-week</th>\n","      <th>native-country</th>\n","      <th>salary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>49</td>\n","      <td>Private</td>\n","      <td>101320</td>\n","      <td>Assoc-acdm</td>\n","      <td>12.0</td>\n","      <td>Married-civ-spouse</td>\n","      <td>NaN</td>\n","      <td>Wife</td>\n","      <td>White</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>1902</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&gt;=50k</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>44</td>\n","      <td>Private</td>\n","      <td>236746</td>\n","      <td>Masters</td>\n","      <td>14.0</td>\n","      <td>Divorced</td>\n","      <td>Exec-managerial</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>10520</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>United-States</td>\n","      <td>&gt;=50k</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>96185</td>\n","      <td>HS-grad</td>\n","      <td>NaN</td>\n","      <td>Divorced</td>\n","      <td>NaN</td>\n","      <td>Unmarried</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>32</td>\n","      <td>United-States</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>38</td>\n","      <td>Self-emp-inc</td>\n","      <td>112847</td>\n","      <td>Prof-school</td>\n","      <td>15.0</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Husband</td>\n","      <td>Asian-Pac-Islander</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&gt;=50k</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>42</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>82297</td>\n","      <td>7th-8th</td>\n","      <td>NaN</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Other-service</td>\n","      <td>Wife</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>50</td>\n","      <td>United-States</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age          workclass  fnlwgt  ... hours-per-week  native-country salary\n","0   49            Private  101320  ...             40   United-States  >=50k\n","1   44            Private  236746  ...             45   United-States  >=50k\n","2   38            Private   96185  ...             32   United-States   <50k\n","3   38       Self-emp-inc  112847  ...             40   United-States  >=50k\n","4   42   Self-emp-not-inc   82297  ...             50   United-States   <50k\n","\n","[5 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"chcugnQRO06s"},"source":["cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n","cont_names = ['age', 'fnlwgt', 'education-num']\n","procs = [Categorify, FillMissing, Normalize]\n","splits = RandomSplitter()(range_of(df_main))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G8tN99dlO06u"},"source":["to = TabularPandas(df_main, procs, cat_names, cont_names, y_names=\"salary\", splits=splits)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O0h9qa8VO06x","executionInfo":{"status":"ok","timestamp":1604215349822,"user_tz":420,"elapsed":1124,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"9fc6394b-d777-416e-e17a-3a95531fd0d4","colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["dls = to.dataloaders()\n","dls.valid.show_batch()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>workclass</th>\n","      <th>education</th>\n","      <th>marital-status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>education-num_na</th>\n","      <th>age</th>\n","      <th>fnlwgt</th>\n","      <th>education-num</th>\n","      <th>salary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Private</td>\n","      <td>Bachelors</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>48.000000</td>\n","      <td>202466.999660</td>\n","      <td>13.0</td>\n","      <td>&gt;=50k</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Private</td>\n","      <td>Some-college</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Craft-repair</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>24.000001</td>\n","      <td>223810.998444</td>\n","      <td>10.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Private</td>\n","      <td>Assoc-acdm</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>30.000000</td>\n","      <td>54608.000867</td>\n","      <td>12.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>39.000000</td>\n","      <td>201409.999946</td>\n","      <td>9.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>State-gov</td>\n","      <td>Some-college</td>\n","      <td>Divorced</td>\n","      <td>Prof-specialty</td>\n","      <td>Not-in-family</td>\n","      <td>Black</td>\n","      <td>False</td>\n","      <td>55.000000</td>\n","      <td>181641.000022</td>\n","      <td>10.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Own-child</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>22.000000</td>\n","      <td>113549.998637</td>\n","      <td>9.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Private</td>\n","      <td>Some-college</td>\n","      <td>Never-married</td>\n","      <td>Craft-repair</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>44.000000</td>\n","      <td>109272.998341</td>\n","      <td>10.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>Divorced</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>52.999999</td>\n","      <td>195638.000069</td>\n","      <td>9.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Private</td>\n","      <td>11th</td>\n","      <td>Never-married</td>\n","      <td>Craft-repair</td>\n","      <td>Other-relative</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>32.000000</td>\n","      <td>375832.999583</td>\n","      <td>7.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Adm-clerical</td>\n","      <td>Wife</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>26.000000</td>\n","      <td>202091.000094</td>\n","      <td>9.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"DFMbUrS9O06z","executionInfo":{"status":"ok","timestamp":1604215358181,"user_tz":420,"elapsed":1305,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"16d1e95e-10f5-47c4-db11-e9018b789ba6","colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["to.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>workclass</th>\n","      <th>education</th>\n","      <th>marital-status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>education-num_na</th>\n","      <th>age</th>\n","      <th>fnlwgt</th>\n","      <th>education-num</th>\n","      <th>salary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1093</th>\n","      <td>?</td>\n","      <td>Some-college</td>\n","      <td>Married-civ-spouse</td>\n","      <td>?</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>66.0</td>\n","      <td>260111.0</td>\n","      <td>10.0</td>\n","      <td>&gt;=50k</td>\n","    </tr>\n","    <tr>\n","      <th>2768</th>\n","      <td>Local-gov</td>\n","      <td>Masters</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>60.0</td>\n","      <td>141637.0</td>\n","      <td>14.0</td>\n","      <td>&gt;=50k</td>\n","    </tr>\n","    <tr>\n","      <th>1917</th>\n","      <td>Private</td>\n","      <td>Some-college</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Craft-repair</td>\n","      <td>Husband</td>\n","      <td>Asian-Pac-Islander</td>\n","      <td>False</td>\n","      <td>49.0</td>\n","      <td>81973.0</td>\n","      <td>10.0</td>\n","      <td>&gt;=50k</td>\n","    </tr>\n","    <tr>\n","      <th>6176</th>\n","      <td>Private</td>\n","      <td>7th-8th</td>\n","      <td>Never-married</td>\n","      <td>Other-service</td>\n","      <td>Own-child</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>39.0</td>\n","      <td>194287.0</td>\n","      <td>4.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","    <tr>\n","      <th>6195</th>\n","      <td>Self-emp-not-inc</td>\n","      <td>HS-grad</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Other-service</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>37.0</td>\n","      <td>35330.0</td>\n","      <td>9.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","    <tr>\n","      <th>6102</th>\n","      <td>Self-emp-not-inc</td>\n","      <td>HS-grad</td>\n","      <td>Divorced</td>\n","      <td>Sales</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>41.0</td>\n","      <td>89942.0</td>\n","      <td>9.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","    <tr>\n","      <th>8214</th>\n","      <td>Private</td>\n","      <td>Bachelors</td>\n","      <td>Never-married</td>\n","      <td>Prof-specialty</td>\n","      <td>Own-child</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>23.0</td>\n","      <td>119838.0</td>\n","      <td>13.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","    <tr>\n","      <th>9562</th>\n","      <td>Private</td>\n","      <td>Doctorate</td>\n","      <td>Divorced</td>\n","      <td>Prof-specialty</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>29.0</td>\n","      <td>195284.0</td>\n","      <td>16.0</td>\n","      <td>&gt;=50k</td>\n","    </tr>\n","    <tr>\n","      <th>1724</th>\n","      <td>Private</td>\n","      <td>10th</td>\n","      <td>Separated</td>\n","      <td>Craft-repair</td>\n","      <td>Unmarried</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>32.0</td>\n","      <td>184833.0</td>\n","      <td>6.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","    <tr>\n","      <th>4423</th>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Machine-op-inspct</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>36.0</td>\n","      <td>437909.0</td>\n","      <td>9.0</td>\n","      <td>&lt;50k</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Dn7beAB2O061"},"source":["We can decode any set of transformed data by calling `to.decode_row` with our raw data:"]},{"cell_type":"code","metadata":{"id":"VqtO40reO061","executionInfo":{"status":"ok","timestamp":1604215390360,"user_tz":420,"elapsed":1095,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"a0efc704-7b4c-427a-8370-d08fc9e12e05","colab":{"base_uri":"https://localhost:8080/"}},"source":["row = to.items.iloc[0]\n","to.decode_row(row)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["age                                  66\n","workclass                             ?\n","fnlwgt                           260111\n","education                  Some-college\n","education-num                        10\n","marital-status       Married-civ-spouse\n","occupation                            ?\n","relationship                    Husband\n","race                              White\n","sex                                Male\n","capital-gain                          0\n","capital-loss                          0\n","hours-per-week                       40\n","native-country            United-States\n","salary                            >=50k\n","education-num_na                  False\n","Name: 1093, dtype: object"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"id":"iTetSIxfO063","executionInfo":{"status":"ok","timestamp":1604215399811,"user_tz":420,"elapsed":1265,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"5e316e98-f9ee-4020-cd98-c853250bc08c","colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["to_tst = to.new(df_test)\n","to_tst.process()\n","to_tst.items.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>workclass</th>\n","      <th>fnlwgt</th>\n","      <th>education</th>\n","      <th>education-num</th>\n","      <th>marital-status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>sex</th>\n","      <th>capital-gain</th>\n","      <th>capital-loss</th>\n","      <th>hours-per-week</th>\n","      <th>native-country</th>\n","      <th>education-num_na</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10000</th>\n","      <td>0.461344</td>\n","      <td>5</td>\n","      <td>1.349813</td>\n","      <td>10</td>\n","      <td>1.173490</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>Philippines</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10001</th>\n","      <td>-0.930039</td>\n","      <td>5</td>\n","      <td>1.262382</td>\n","      <td>12</td>\n","      <td>-0.431008</td>\n","      <td>3</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10002</th>\n","      <td>1.047189</td>\n","      <td>5</td>\n","      <td>0.154538</td>\n","      <td>2</td>\n","      <td>-1.233257</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>37</td>\n","      <td>United-States</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10003</th>\n","      <td>0.534575</td>\n","      <td>5</td>\n","      <td>-0.280595</td>\n","      <td>12</td>\n","      <td>-0.431008</td>\n","      <td>7</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>43</td>\n","      <td>United-States</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10004</th>\n","      <td>0.754267</td>\n","      <td>6</td>\n","      <td>1.452827</td>\n","      <td>9</td>\n","      <td>0.371241</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>60</td>\n","      <td>United-States</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            age  workclass  ...  native-country  education-num_na\n","10000  0.461344          5  ...     Philippines                 1\n","10001 -0.930039          5  ...   United-States                 1\n","10002  1.047189          5  ...   United-States                 1\n","10003  0.534575          5  ...   United-States                 1\n","10004  0.754267          6  ...   United-States                 1\n","\n","[5 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"YQOnzxdGO065","executionInfo":{"status":"ok","timestamp":1604215406262,"user_tz":420,"elapsed":1086,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"49f8cd3b-366b-4034-8a7c-77ab8638d563","colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["tst_dl = dls.valid.new(to_tst)\n","tst_dl.show_batch()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>workclass</th>\n","      <th>education</th>\n","      <th>marital-status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>education-num_na</th>\n","      <th>age</th>\n","      <th>fnlwgt</th>\n","      <th>education-num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Private</td>\n","      <td>Bachelors</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Adm-clerical</td>\n","      <td>Husband</td>\n","      <td>Asian-Pac-Islander</td>\n","      <td>False</td>\n","      <td>45.000000</td>\n","      <td>338104.998726</td>\n","      <td>13.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Transport-moving</td>\n","      <td>Husband</td>\n","      <td>Other</td>\n","      <td>False</td>\n","      <td>26.000000</td>\n","      <td>328663.005114</td>\n","      <td>9.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Private</td>\n","      <td>11th</td>\n","      <td>Divorced</td>\n","      <td>Other-service</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>52.999999</td>\n","      <td>209021.999726</td>\n","      <td>7.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>Widowed</td>\n","      <td>Adm-clerical</td>\n","      <td>Unmarried</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>46.000000</td>\n","      <td>162030.000378</td>\n","      <td>9.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Self-emp-inc</td>\n","      <td>Assoc-voc</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>49.000000</td>\n","      <td>349230.002765</td>\n","      <td>11.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Local-gov</td>\n","      <td>Some-college</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>34.000000</td>\n","      <td>124826.998872</td>\n","      <td>10.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Self-emp-inc</td>\n","      <td>Some-college</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Sales</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>52.999999</td>\n","      <td>290639.997877</td>\n","      <td>10.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Private</td>\n","      <td>Some-college</td>\n","      <td>Never-married</td>\n","      <td>Sales</td>\n","      <td>Own-child</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>19.000000</td>\n","      <td>106273.002965</td>\n","      <td>10.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Private</td>\n","      <td>Some-college</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Protective-serv</td>\n","      <td>Husband</td>\n","      <td>Black</td>\n","      <td>False</td>\n","      <td>72.000001</td>\n","      <td>53683.999433</td>\n","      <td>10.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Private</td>\n","      <td>Some-college</td>\n","      <td>Never-married</td>\n","      <td>Sales</td>\n","      <td>Own-child</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>19.999999</td>\n","      <td>505980.004135</td>\n","      <td>10.0</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"URsO9ESnO067"},"source":["## Other target types"]},{"cell_type":"markdown","metadata":{"id":"bIaE4VTuO068"},"source":["### Multi-label categories"]},{"cell_type":"markdown","metadata":{"id":"tDvyxDrYO068"},"source":["#### one-hot encoded label"]},{"cell_type":"code","metadata":{"id":"rofylNAvO068"},"source":["def _mock_multi_label(df):\n","    sal,sex,white = [],[],[]\n","    for row in df.itertuples():\n","        sal.append(row.salary == '>=50k')\n","        sex.append(row.sex == ' Male')\n","        white.append(row.race == ' White')\n","    df['salary'] = np.array(sal)\n","    df['male']   = np.array(sex)\n","    df['white']  = np.array(white)\n","    return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XosqqQp4O06-"},"source":["path = untar_data(URLs.ADULT_SAMPLE)\n","df = pd.read_csv(path/'adult.csv')\n","df_main,df_test = df.iloc[:10000].copy(),df.iloc[10000:].copy()\n","df_main = _mock_multi_label(df_main)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g1xB0yVmO07B","executionInfo":{"status":"ok","timestamp":1604215432327,"user_tz":420,"elapsed":1232,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"715de887-e93b-4935-b580-1ade95865eb9","colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["df_main.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>workclass</th>\n","      <th>fnlwgt</th>\n","      <th>education</th>\n","      <th>education-num</th>\n","      <th>marital-status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>sex</th>\n","      <th>capital-gain</th>\n","      <th>capital-loss</th>\n","      <th>hours-per-week</th>\n","      <th>native-country</th>\n","      <th>salary</th>\n","      <th>male</th>\n","      <th>white</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>49</td>\n","      <td>Private</td>\n","      <td>101320</td>\n","      <td>Assoc-acdm</td>\n","      <td>12.0</td>\n","      <td>Married-civ-spouse</td>\n","      <td>NaN</td>\n","      <td>Wife</td>\n","      <td>White</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>1902</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>44</td>\n","      <td>Private</td>\n","      <td>236746</td>\n","      <td>Masters</td>\n","      <td>14.0</td>\n","      <td>Divorced</td>\n","      <td>Exec-managerial</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>10520</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>United-States</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>96185</td>\n","      <td>HS-grad</td>\n","      <td>NaN</td>\n","      <td>Divorced</td>\n","      <td>NaN</td>\n","      <td>Unmarried</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>32</td>\n","      <td>United-States</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>38</td>\n","      <td>Self-emp-inc</td>\n","      <td>112847</td>\n","      <td>Prof-school</td>\n","      <td>15.0</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Husband</td>\n","      <td>Asian-Pac-Islander</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>42</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>82297</td>\n","      <td>7th-8th</td>\n","      <td>NaN</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Other-service</td>\n","      <td>Wife</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>50</td>\n","      <td>United-States</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age          workclass  fnlwgt  ... salary   male  white\n","0   49            Private  101320  ...   True  False   True\n","1   44            Private  236746  ...   True   True   True\n","2   38            Private   96185  ...  False  False  False\n","3   38       Self-emp-inc  112847  ...   True   True  False\n","4   42   Self-emp-not-inc   82297  ...  False  False  False\n","\n","[5 rows x 17 columns]"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"HGJh2xTOO07F"},"source":["#export\n","@EncodedMultiCategorize\n","def setups(self, to:Tabular):\n","    self.c = len(self.vocab)\n","    return self(to)\n","\n","@EncodedMultiCategorize\n","def encodes(self, to:Tabular): return to\n","\n","@EncodedMultiCategorize\n","def decodes(self, to:Tabular):\n","    to.transform(to.y_names, lambda c: c==1)\n","    return to"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i2J9-JhKO07H"},"source":["cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n","cont_names = ['age', 'fnlwgt', 'education-num']\n","procs = [Categorify, FillMissing, Normalize]\n","splits = RandomSplitter()(range_of(df_main))\n","y_names=[\"salary\", \"male\", \"white\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4eJY_SADO07J","executionInfo":{"status":"ok","timestamp":1604215450776,"user_tz":420,"elapsed":1154,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"0604ef5e-65f2-4649-9b99-bb607fb45867","colab":{"base_uri":"https://localhost:8080/"}},"source":["%time to = TabularPandas(df_main, procs, cat_names, cont_names, y_names=y_names, y_block=MultiCategoryBlock(encoded=True, vocab=y_names), splits=splits)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 73.8 ms, sys: 0 ns, total: 73.8 ms\n","Wall time: 75.2 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GyVPfwNFO07L","executionInfo":{"status":"ok","timestamp":1604215452277,"user_tz":420,"elapsed":1014,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"68566cc5-1db6-4ced-ff64-d6176953a8cc","colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["dls = to.dataloaders()\n","dls.valid.show_batch()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>workclass</th>\n","      <th>education</th>\n","      <th>marital-status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>education-num_na</th>\n","      <th>age</th>\n","      <th>fnlwgt</th>\n","      <th>education-num</th>\n","      <th>salary</th>\n","      <th>male</th>\n","      <th>white</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>Never-married</td>\n","      <td>Craft-repair</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>44.000000</td>\n","      <td>221171.998543</td>\n","      <td>9.0</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Self-emp-not-inc</td>\n","      <td>Assoc-voc</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Farming-fishing</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>28.000000</td>\n","      <td>39388.002873</td>\n","      <td>11.0</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Private</td>\n","      <td>Bachelors</td>\n","      <td>Never-married</td>\n","      <td>Prof-specialty</td>\n","      <td>Own-child</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>24.000001</td>\n","      <td>126612.998240</td>\n","      <td>13.0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Unmarried</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>30.000000</td>\n","      <td>45781.000285</td>\n","      <td>9.0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>Married-civ-spouse</td>\n","      <td>#na#</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>True</td>\n","      <td>40.000000</td>\n","      <td>104196.002008</td>\n","      <td>10.0</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Self-emp-not-inc</td>\n","      <td>Masters</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>58.000001</td>\n","      <td>130714.002950</td>\n","      <td>14.0</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Private</td>\n","      <td>11th</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Unmarried</td>\n","      <td>Black</td>\n","      <td>False</td>\n","      <td>23.000001</td>\n","      <td>177087.000463</td>\n","      <td>7.0</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Craft-repair</td>\n","      <td>Husband</td>\n","      <td>Asian-Pac-Islander</td>\n","      <td>False</td>\n","      <td>36.000000</td>\n","      <td>99871.998153</td>\n","      <td>9.0</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Self-emp-inc</td>\n","      <td>Bachelors</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>54.000001</td>\n","      <td>129431.998305</td>\n","      <td>13.0</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Private</td>\n","      <td>Assoc-voc</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Craft-repair</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>47.000000</td>\n","      <td>326856.996506</td>\n","      <td>11.0</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"DfwppMuwO07M"},"source":["#### Not one-hot encoded"]},{"cell_type":"code","metadata":{"id":"nllavAibO07N"},"source":["def _mock_multi_label(df):\n","    targ = []\n","    for row in df.itertuples():\n","        labels = []\n","        if row.salary == '>=50k': labels.append('>50k')\n","        if row.sex == ' Male':   labels.append('male')\n","        if row.race == ' White': labels.append('white')\n","        targ.append(' '.join(labels))\n","    df['target'] = np.array(targ)\n","    return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DXoRsTSrO07O"},"source":["path = untar_data(URLs.ADULT_SAMPLE)\n","df = pd.read_csv(path/'adult.csv')\n","df_main,df_test = df.iloc[:10000].copy(),df.iloc[10000:].copy()\n","df_main = _mock_multi_label(df_main)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fhY4pFYAO07Q","executionInfo":{"status":"ok","timestamp":1604215471761,"user_tz":420,"elapsed":1226,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"2171b66d-b621-4371-ce52-bbd3ce443101","colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["df_main.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>workclass</th>\n","      <th>fnlwgt</th>\n","      <th>education</th>\n","      <th>education-num</th>\n","      <th>marital-status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>sex</th>\n","      <th>capital-gain</th>\n","      <th>capital-loss</th>\n","      <th>hours-per-week</th>\n","      <th>native-country</th>\n","      <th>salary</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>49</td>\n","      <td>Private</td>\n","      <td>101320</td>\n","      <td>Assoc-acdm</td>\n","      <td>12.0</td>\n","      <td>Married-civ-spouse</td>\n","      <td>NaN</td>\n","      <td>Wife</td>\n","      <td>White</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>1902</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&gt;=50k</td>\n","      <td>&gt;50k white</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>44</td>\n","      <td>Private</td>\n","      <td>236746</td>\n","      <td>Masters</td>\n","      <td>14.0</td>\n","      <td>Divorced</td>\n","      <td>Exec-managerial</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>10520</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>United-States</td>\n","      <td>&gt;=50k</td>\n","      <td>&gt;50k male white</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>96185</td>\n","      <td>HS-grad</td>\n","      <td>NaN</td>\n","      <td>Divorced</td>\n","      <td>NaN</td>\n","      <td>Unmarried</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>32</td>\n","      <td>United-States</td>\n","      <td>&lt;50k</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>38</td>\n","      <td>Self-emp-inc</td>\n","      <td>112847</td>\n","      <td>Prof-school</td>\n","      <td>15.0</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Husband</td>\n","      <td>Asian-Pac-Islander</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&gt;=50k</td>\n","      <td>&gt;50k male</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>42</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>82297</td>\n","      <td>7th-8th</td>\n","      <td>NaN</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Other-service</td>\n","      <td>Wife</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>50</td>\n","      <td>United-States</td>\n","      <td>&lt;50k</td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age          workclass  fnlwgt  ...  native-country  salary           target\n","0   49            Private  101320  ...   United-States   >=50k       >50k white\n","1   44            Private  236746  ...   United-States   >=50k  >50k male white\n","2   38            Private   96185  ...   United-States    <50k                 \n","3   38       Self-emp-inc  112847  ...   United-States   >=50k        >50k male\n","4   42   Self-emp-not-inc   82297  ...   United-States    <50k                 \n","\n","[5 rows x 16 columns]"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"TAdV_z-OO07T"},"source":["@MultiCategorize\n","def encodes(self, to:Tabular): \n","    #to.transform(to.y_names, partial(_apply_cats, {n: self.vocab for n in to.y_names}, 0))\n","    return to\n","  \n","@MultiCategorize\n","def decodes(self, to:Tabular): \n","    #to.transform(to.y_names, partial(_decode_cats, {n: self.vocab for n in to.y_names}))\n","    return to"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"090ZyQYhO07V"},"source":["cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n","cont_names = ['age', 'fnlwgt', 'education-num']\n","procs = [Categorify, FillMissing, Normalize]\n","splits = RandomSplitter()(range_of(df_main))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOxUeMavO07W","executionInfo":{"status":"ok","timestamp":1604215485617,"user_tz":420,"elapsed":741,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"df2d343e-58dd-40ab-83cb-ccea2aa981a1","colab":{"base_uri":"https://localhost:8080/"}},"source":["%time to = TabularPandas(df_main, procs, cat_names, cont_names, y_names=\"target\", y_block=MultiCategoryBlock(), splits=splits)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 73.8 ms, sys: 1.13 ms, total: 74.9 ms\n","Wall time: 77.1 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HBqLcccMO07Y","executionInfo":{"status":"ok","timestamp":1604215489019,"user_tz":420,"elapsed":1299,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"967b31b1-9ebe-4342-af19-5238ac8cf468","colab":{"base_uri":"https://localhost:8080/"}},"source":["to.procs[2].vocab"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['-', '_', 'a', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y']"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"markdown","metadata":{"id":"ldXivbusO07a"},"source":["### Regression"]},{"cell_type":"code","metadata":{"id":"LByDb9lyO07a"},"source":["#export\n","@RegressionSetup\n","def setups(self, to:Tabular):\n","    if self.c is not None: return\n","    self.c = len(to.y_names)\n","    return to\n","\n","@RegressionSetup\n","def encodes(self, to:Tabular): return to\n","\n","@RegressionSetup\n","def decodes(self, to:Tabular): return to"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bmV0zDnbO07d"},"source":["path = untar_data(URLs.ADULT_SAMPLE)\n","df = pd.read_csv(path/'adult.csv')\n","df_main,df_test = df.iloc[:10000].copy(),df.iloc[10000:].copy()\n","df_main = _mock_multi_label(df_main)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4b2Z0onsO07f"},"source":["cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n","cont_names = ['fnlwgt', 'education-num']\n","procs = [Categorify, FillMissing, Normalize]\n","splits = RandomSplitter()(range_of(df_main))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EReqTvAtO07k","executionInfo":{"status":"ok","timestamp":1604215507277,"user_tz":420,"elapsed":1235,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"f9901e93-e91b-4e16-a9d6-ff0b1c2075c3","colab":{"base_uri":"https://localhost:8080/"}},"source":["%time to = TabularPandas(df_main, procs, cat_names, cont_names, y_names='age', splits=splits)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 85.6 ms, sys: 1.4 ms, total: 87 ms\n","Wall time: 92.8 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MPncAOTsO07m","executionInfo":{"status":"ok","timestamp":1604215509000,"user_tz":420,"elapsed":1153,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"48f049f7-8a27-4b71-e10a-80b1a1e34c17","colab":{"base_uri":"https://localhost:8080/"}},"source":["to.procs[-1].means"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'education-num': 10.0625, 'fnlwgt': 192767.350625}"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"code","metadata":{"id":"hOnUWCB3O07o","executionInfo":{"status":"ok","timestamp":1604215511415,"user_tz":420,"elapsed":865,"user":{"displayName":"Srinivas Raman","photoUrl":"","userId":"10288249463255174028"}},"outputId":"572be7c8-d49f-429f-eb00-d352598b8393","colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["dls = to.dataloaders()\n","dls.valid.show_batch()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>workclass</th>\n","      <th>education</th>\n","      <th>marital-status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>education-num_na</th>\n","      <th>fnlwgt</th>\n","      <th>education-num</th>\n","      <th>age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Private</td>\n","      <td>Bachelors</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>125784.000982</td>\n","      <td>13.0</td>\n","      <td>76.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Local-gov</td>\n","      <td>Bachelors</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>160472.001568</td>\n","      <td>13.0</td>\n","      <td>45.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Self-emp-not-inc</td>\n","      <td>HS-grad</td>\n","      <td>Never-married</td>\n","      <td>Sales</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>195123.999982</td>\n","      <td>9.0</td>\n","      <td>41.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Private</td>\n","      <td>Bachelors</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>303154.995525</td>\n","      <td>13.0</td>\n","      <td>42.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Self-emp-inc</td>\n","      <td>HS-grad</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Wife</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>154536.999077</td>\n","      <td>9.0</td>\n","      <td>58.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>?</td>\n","      <td>HS-grad</td>\n","      <td>Never-married</td>\n","      <td>?</td>\n","      <td>Own-child</td>\n","      <td>Amer-Indian-Eskimo</td>\n","      <td>False</td>\n","      <td>99483.000273</td>\n","      <td>9.0</td>\n","      <td>31.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Private</td>\n","      <td>Bachelors</td>\n","      <td>Divorced</td>\n","      <td>Exec-managerial</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>51099.994821</td>\n","      <td>13.0</td>\n","      <td>38.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Other-relative</td>\n","      <td>Black</td>\n","      <td>False</td>\n","      <td>429346.003824</td>\n","      <td>9.0</td>\n","      <td>22.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>?</td>\n","      <td>Some-college</td>\n","      <td>Never-married</td>\n","      <td>?</td>\n","      <td>Own-child</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>205940.000277</td>\n","      <td>10.0</td>\n","      <td>21.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>?</td>\n","      <td>11th</td>\n","      <td>Married-civ-spouse</td>\n","      <td>?</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>False</td>\n","      <td>49193.999511</td>\n","      <td>7.0</td>\n","      <td>64.0</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"HgAeYLwnO07q"},"source":["## Not being used now - for multi-modal"]},{"cell_type":"code","metadata":{"id":"N6Eoh3A6O07q"},"source":["class TensorTabular(fastuple):\n","    def get_ctxs(self, max_n=10, **kwargs):\n","        n_samples = min(self[0].shape[0], max_n)\n","        df = pd.DataFrame(index = range(n_samples))\n","        return [df.iloc[i] for i in range(n_samples)]\n","\n","    def display(self, ctxs): display_df(pd.DataFrame(ctxs))\n","\n","class TabularLine(pd.Series):\n","    \"A line of a dataframe that knows how to show itself\"\n","    def show(self, ctx=None, **kwargs): return self if ctx is None else ctx.append(self)\n","\n","class ReadTabLine(ItemTransform):\n","    def __init__(self, proc): self.proc = proc\n","\n","    def encodes(self, row):\n","        cats,conts = (o.map(row.__getitem__) for o in (self.proc.cat_names,self.proc.cont_names))\n","        return TensorTabular(tensor(cats).long(),tensor(conts).float())\n","\n","    def decodes(self, o):\n","        to = TabularPandas(o, self.proc.cat_names, self.proc.cont_names, self.proc.y_names)\n","        to = self.proc.decode(to)\n","        return TabularLine(pd.Series({c: v for v,c in zip(to.items[0]+to.items[1], self.proc.cat_names+self.proc.cont_names)}))\n","\n","class ReadTabTarget(ItemTransform):\n","    def __init__(self, proc): self.proc = proc\n","    def encodes(self, row): return row[self.proc.y_names].astype(np.int64)\n","    def decodes(self, o): return Category(self.proc.classes[self.proc.y_names][o])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kqscJQMNO07s"},"source":["# tds = TfmdDS(to.items, tfms=[[ReadTabLine(proc)], ReadTabTarget(proc)])\n","# enc = tds[1]\n","# test_eq(enc[0][0], tensor([2,1]))\n","# test_close(enc[0][1], tensor([-0.628828]))\n","# test_eq(enc[1], 1)\n","\n","# dec = tds.decode(enc)\n","# assert isinstance(dec[0], TabularLine)\n","# test_close(dec[0], pd.Series({'a': 1, 'b_na': False, 'b': 1}))\n","# test_eq(dec[1], 'a')\n","\n","# test_stdout(lambda: print(show_at(tds, 1)), \"\"\"a               1\n","# b_na        False\n","# b               1\n","# category        a\n","# dtype: object\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HAjW3D4sO07u"},"source":["## Export -"]},{"cell_type":"code","metadata":{"id":"bY_rXf-GO07u","outputId":"bab913f0-cfe6-4a7d-ad72-278df6bb5dfd"},"source":["#hide\n","from nbdev.export import notebook2script\n","notebook2script()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Converted 00_torch_core.ipynb.\n","Converted 01_layers.ipynb.\n","Converted 02_data.load.ipynb.\n","Converted 03_data.core.ipynb.\n","Converted 04_data.external.ipynb.\n","Converted 05_data.transforms.ipynb.\n","Converted 06_data.block.ipynb.\n","Converted 07_vision.core.ipynb.\n","Converted 08_vision.data.ipynb.\n","Converted 09_vision.augment.ipynb.\n","Converted 09b_vision.utils.ipynb.\n","Converted 09c_vision.widgets.ipynb.\n","Converted 10_tutorial.pets.ipynb.\n","Converted 11_vision.models.xresnet.ipynb.\n","Converted 12_optimizer.ipynb.\n","Converted 13_callback.core.ipynb.\n","Converted 13a_learner.ipynb.\n","Converted 13b_metrics.ipynb.\n","Converted 14_callback.schedule.ipynb.\n","Converted 14a_callback.data.ipynb.\n","Converted 15_callback.hook.ipynb.\n","Converted 15a_vision.models.unet.ipynb.\n","Converted 16_callback.progress.ipynb.\n","Converted 17_callback.tracker.ipynb.\n","Converted 18_callback.fp16.ipynb.\n","Converted 18a_callback.training.ipynb.\n","Converted 19_callback.mixup.ipynb.\n","Converted 20_interpret.ipynb.\n","Converted 20a_distributed.ipynb.\n","Converted 21_vision.learner.ipynb.\n","Converted 22_tutorial.imagenette.ipynb.\n","Converted 23_tutorial.vision.ipynb.\n","Converted 24_tutorial.siamese.ipynb.\n","Converted 24_vision.gan.ipynb.\n","Converted 30_text.core.ipynb.\n","Converted 31_text.data.ipynb.\n","Converted 32_text.models.awdlstm.ipynb.\n","Converted 33_text.models.core.ipynb.\n","Converted 34_callback.rnn.ipynb.\n","Converted 35_tutorial.wikitext.ipynb.\n","Converted 36_text.models.qrnn.ipynb.\n","Converted 37_text.learner.ipynb.\n","Converted 38_tutorial.text.ipynb.\n","Converted 39_tutorial.transformers.ipynb.\n","Converted 40_tabular.core.ipynb.\n","Converted 41_tabular.data.ipynb.\n","Converted 42_tabular.model.ipynb.\n","Converted 43_tabular.learner.ipynb.\n","Converted 44_tutorial.tabular.ipynb.\n","Converted 45_collab.ipynb.\n","Converted 46_tutorial.collab.ipynb.\n","Converted 50_tutorial.datablock.ipynb.\n","Converted 60_medical.imaging.ipynb.\n","Converted 61_tutorial.medical_imaging.ipynb.\n","Converted 65_medical.text.ipynb.\n","Converted 70_callback.wandb.ipynb.\n","Converted 71_callback.tensorboard.ipynb.\n","Converted 72_callback.neptune.ipynb.\n","Converted 73_callback.captum.ipynb.\n","Converted 74_callback.cutmix.ipynb.\n","Converted 97_test_utils.ipynb.\n","Converted 99_pytorch_doc.ipynb.\n","Converted dev-setup.ipynb.\n","Converted index.ipynb.\n","Converted quick_start.ipynb.\n","Converted tutorial.ipynb.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5EzpWpmfO07w"},"source":[""],"execution_count":null,"outputs":[]}]}